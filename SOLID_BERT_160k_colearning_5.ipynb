{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Trainer (has labels)\n",
    "trainer_df = pd.read_csv('datasets/cleaned_SOLIDtest6K_trainer.tsv', sep=\"\\t\")\n",
    "learner_tweets_df = pd.read_csv('datasets/cleaned_SOLID9M_learner.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# trainer_labels = trainer_df['label'].values\n",
    "# trainer_tweets = trainer_df['tweet'].values\n",
    "learner_tweets_df['labels'] = learner_tweets_df['average'].apply(lambda x: 1 if x >= 0.5 else 0) # threshold the average values\n",
    "\n",
    "sample_size = 160000\n",
    "positive_ratio = 0.75\n",
    "\n",
    "# Select the most confident positive values\n",
    "semi_tweets_pos_df = learner_tweets_df[learner_tweets_df['average'] > 0.8].sample(n=np.floor(sample_size*positive_ratio).astype(int), random_state=1)\n",
    "\n",
    "# Select the most confident negative values\n",
    "semi_tweets_neg_df = learner_tweets_df[learner_tweets_df['average'] < 0.3].sample(n=np.floor(sample_size*(1-positive_ratio)).astype(int), random_state=1)\n",
    "\n",
    "semi_tweets_df = pd.concat([semi_tweets_pos_df, semi_tweets_neg_df])\n",
    "semi_tweets_df = semi_tweets_df.sample(frac=1, random_state=42)\n",
    "\n",
    "semi_tweets = semi_tweets_df['text'].values\n",
    "semi_labels = semi_tweets_df['labels'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>average</th>\n",
       "      <th>std</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>720722</th>\n",
       "      <td>1162312887454580737</td>\n",
       "      <td>invited to miami to help with the launch of a ...</td>\n",
       "      <td>0.148270</td>\n",
       "      <td>0.157680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603467</th>\n",
       "      <td>1161419177640337408</td>\n",
       "      <td>this a loser ass tweetmy girlfriend tried gett...</td>\n",
       "      <td>0.800986</td>\n",
       "      <td>0.150405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8173685</th>\n",
       "      <td>1188230271944069121</td>\n",
       "      <td>how can someone be a whole ass mom and talk sh...</td>\n",
       "      <td>0.860020</td>\n",
       "      <td>0.160765</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885021</th>\n",
       "      <td>1157093416632758278</td>\n",
       "      <td>dating females is so extra g you wake up from ...</td>\n",
       "      <td>0.805068</td>\n",
       "      <td>0.145025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443345</th>\n",
       "      <td>1161927959038582784</td>\n",
       "      <td>niggas fresh out of jail can taaalkkk they ass...</td>\n",
       "      <td>0.863823</td>\n",
       "      <td>0.158069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490726</th>\n",
       "      <td>1161269218668683264</td>\n",
       "      <td>cleared accident i sb cumberland blvd cobb co a</td>\n",
       "      <td>0.220624</td>\n",
       "      <td>0.140261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7116560</th>\n",
       "      <td>1186806186508767232</td>\n",
       "      <td>do not introduce me to a vibe you cannot lol s...</td>\n",
       "      <td>0.843347</td>\n",
       "      <td>0.161567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402352</th>\n",
       "      <td>1159820019473231882</td>\n",
       "      <td>and when she is home he follows her everywhere...</td>\n",
       "      <td>0.234806</td>\n",
       "      <td>0.180824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453508</th>\n",
       "      <td>1159757935016402950</td>\n",
       "      <td>if you think ole is out of his depth at mufc p...</td>\n",
       "      <td>0.829519</td>\n",
       "      <td>0.162993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029290</th>\n",
       "      <td>1158407872776212482</td>\n",
       "      <td>everyday i am reminded of how ambitious it is ...</td>\n",
       "      <td>0.172051</td>\n",
       "      <td>0.166352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id  \\\n",
       "720722   1162312887454580737   \n",
       "3603467  1161419177640337408   \n",
       "8173685  1188230271944069121   \n",
       "3885021  1157093416632758278   \n",
       "3443345  1161927959038582784   \n",
       "1490726  1161269218668683264   \n",
       "7116560  1186806186508767232   \n",
       "2402352  1159820019473231882   \n",
       "1453508  1159757935016402950   \n",
       "5029290  1158407872776212482   \n",
       "\n",
       "                                                      text   average  \\\n",
       "720722   invited to miami to help with the launch of a ...  0.148270   \n",
       "3603467  this a loser ass tweetmy girlfriend tried gett...  0.800986   \n",
       "8173685  how can someone be a whole ass mom and talk sh...  0.860020   \n",
       "3885021  dating females is so extra g you wake up from ...  0.805068   \n",
       "3443345  niggas fresh out of jail can taaalkkk they ass...  0.863823   \n",
       "1490726    cleared accident i sb cumberland blvd cobb co a  0.220624   \n",
       "7116560  do not introduce me to a vibe you cannot lol s...  0.843347   \n",
       "2402352  and when she is home he follows her everywhere...  0.234806   \n",
       "1453508  if you think ole is out of his depth at mufc p...  0.829519   \n",
       "5029290  everyday i am reminded of how ambitious it is ...  0.172051   \n",
       "\n",
       "              std  labels  \n",
       "720722   0.157680       0  \n",
       "3603467  0.150405       1  \n",
       "8173685  0.160765       1  \n",
       "3885021  0.145025       1  \n",
       "3443345  0.158069       1  \n",
       "1490726  0.140261       0  \n",
       "7116560  0.161567       1  \n",
       "2402352  0.180824       0  \n",
       "1453508  0.162993       1  \n",
       "5029290  0.166352       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_tweets_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            return {\n",
    "                'text': text,\n",
    "                'label': label\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'text': text\n",
    "            }\n",
    "        \n",
    "# trainer_dataset = TweetDataset(trainer_tweets, trainer_labels)\n",
    "learner_dataset = TweetDataset(semi_tweets, semi_labels)\n",
    "\n",
    "# trainer_loader = DataLoader(trainer_dataset, batch_size=12, shuffle=True)\n",
    "learner_loader = DataLoader(learner_dataset, batch_size=6, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cymn/miniconda3/envs/nvidia-newest/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('models/OLID_BERT_1', num_labels=2)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26667 [00:00<?, ?it/s]/tmp/ipykernel_8464/1995336368.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(batch['label']).clone().detach().to(device)\n",
      "100%|██████████| 26667/26667 [26:41<00:00, 16.65it/s]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    # trainer_dataloader_iterator = iter(trainer_loader)\n",
    "    semi_labeled_dataloader_iterator = iter(learner_loader)\n",
    "    num_batches = len(learner_loader)\n",
    "    # num_batches = 5000\n",
    "    for _ in tqdm(range(num_batches)):\n",
    "        # Train on labeled data\n",
    "        batch = next(semi_labeled_dataloader_iterator, None)\n",
    "        if batch is not None:\n",
    "            inputs = tokenizer(batch['text'], padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "            labels = torch.tensor(batch['label']).clone().detach().to(device)\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('models/SOLID_BERT_160k_colearning_5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvidia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
